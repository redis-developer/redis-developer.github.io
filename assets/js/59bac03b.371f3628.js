"use strict";(self.webpackChunkredis_developer_hub=self.webpackChunkredis_developer_hub||[]).push([[7903],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return d}});var r=n(67294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function a(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,i=function(e,t){if(null==e)return{};var n,r,i={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=r.createContext({}),c=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):a(a({},t),e)),n},p=function(e){var t=c(e.components);return r.createElement(l.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},u=r.forwardRef((function(e,t){var n=e.components,i=e.mdxType,o=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=c(n),d=i,f=u["".concat(l,".").concat(d)]||u[d]||m[d]||o;return n?r.createElement(f,a(a({ref:t},p),{},{components:n})):r.createElement(f,a({ref:t},p))}));function d(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=n.length,a=new Array(o);a[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:i,a[1]=s;for(var c=2;c<o;c++)a[c]=n[c];return r.createElement.apply(null,a)}return r.createElement.apply(null,n)}u.displayName="MDXCreateElement"},30458:function(e,t,n){n.r(t),n.d(t,{assets:function(){return p},contentTitle:function(){return l},default:function(){return d},frontMatter:function(){return s},metadata:function(){return c},toc:function(){return m}});var r=n(87462),i=n(63366),o=(n(67294),n(3905)),a=(n(44996),["components"]),s={id:"index-client-performance-improvements",title:"1.4 Client Performance Improvements",sidebar_label:"1.4 Client Performance Improvements",slug:"/operate/redis-at-scale/talking-to-redis/client-performance-improvements",custom_edit_url:null},l=void 0,c={unversionedId:"operate/redis-at-scale/talking-to-redis/client-performance-improvements/index-client-performance-improvements",id:"operate/redis-at-scale/talking-to-redis/client-performance-improvements/index-client-performance-improvements",title:"1.4 Client Performance Improvements",description:"Connection management - Pooling",source:"@site/docs/operate/redis-at-scale/talking-to-redis/client-performance-improvements/index-client-performance-improvements.mdx",sourceDirName:"operate/redis-at-scale/talking-to-redis/client-performance-improvements",slug:"/operate/redis-at-scale/talking-to-redis/client-performance-improvements",permalink:"/operate/redis-at-scale/talking-to-redis/client-performance-improvements",draft:!1,editUrl:null,tags:[],version:"current",lastUpdatedAt:1655485542,formattedLastUpdatedAt:"6/17/2022",frontMatter:{id:"index-client-performance-improvements",title:"1.4 Client Performance Improvements",sidebar_label:"1.4 Client Performance Improvements",slug:"/operate/redis-at-scale/talking-to-redis/client-performance-improvements",custom_edit_url:null},sidebar:"docs",previous:{title:"1.3 Redis Clients",permalink:"/operate/redis-at-scale/talking-to-redis/redis-clients"},next:{title:"1.5 Initial Tuning",permalink:"/operate/redis-at-scale/talking-to-redis/initial-tuning"}},p={},m=[{value:"Connection management - Pooling",id:"connection-management---pooling",level:2},{value:"Pipelining",id:"pipelining",level:2}],u={toc:m};function d(e){var t=e.components,n=(0,i.Z)(e,a);return(0,o.kt)("wrapper",(0,r.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h2",{id:"connection-management---pooling"},"Connection management - Pooling"),(0,o.kt)("p",null,"As we showed in the previous section, Redis clients are responsible for managing connections to the Redis server. Creating and recreating new connections over and over again, creates a lot of unnecessary load on the server. A good client library will offer some way of optimizing connection management, by setting up a connection pool, for example.\nWith connection pooling, the client library will instantiate a series of (persistent) connections to the Redis server and keep them open. When the application needs to send a request, the current thread will get one of these connections from the pool, use it, and return it when done."),(0,o.kt)("br",null),(0,o.kt)("img",{src:"https://s3.us-east-2.amazonaws.com/assets-university.redislabs.com/ru301/1.5/image1.png",alt:"Connection Pool diagram"}),(0,o.kt)("br",null),"So if possible, always try to choose a client library that supports pooling connections, because that decision alone can have a huge influence on your system\u2019s performance.",(0,o.kt)("h2",{id:"pipelining"},"Pipelining"),(0,o.kt)("p",null,"As in any client-server application, Redis can handle many clients simultaneously.\nEach client does a (typically blocking) read on a socket and waits for the server response. The server reads the request from the socket, parses it, processes it, and writes the response to the socket. The time the data packets take to travel from the client to the server, and then back again, is called network round trip time, or ",(0,o.kt)("strong",null,"RTT"),".\nIf, for example, you needed to execute 50 commands, you would have to send a request and wait for the response 50 times, paying the ",(0,o.kt)("strong",null,"RTT")," cost every single time. To tackle this problem, Redis can process new requests even if the client hasn't already read the old responses. This way, you can send multiple commands to the server without waiting for the replies at all; the replies are read in the end, in a single step."),(0,o.kt)("br",null),(0,o.kt)("img",{height:"75%",width:"75%",src:"https://s3.us-east-2.amazonaws.com/assets-university.redislabs.com/ru301/1.5/image2.png",alt:"Pipelining diagram"}),(0,o.kt)("br",null),"This technique is called pipelining and is another good way to improve the performance of your system. Most Redis libraries support this technique out of the box.",(0,o.kt)("hr",null),(0,o.kt)("p",null,"Supplemental Reading:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://redis.io/topics/pipelining"},"Redis Pipelining")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://redis.io/topics/clients"},"Redis Client Handling")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://redislabs.com/blog/connection-pools-for-serverless-functions-and-backend-services/"},"Connection Pools for Serverless Functions and Backend Services"))))}d.isMDXComponent=!0}}]);