---
id: index-solutions-interservice-communication
title: Microservices Communication with Redis streams
sidebar_label: Microservices Communication with Redis streams
slug: /howtos/solutions/interservice-communication
authors: [prasan, will]
---

import Authors from '@theme/Authors';
import MicroservicesEcommerceDesign from '../common-data/microservices-ecommerce.mdx';
import MicroservicesArchitectureWithRedis from '../common-data/microservices-arch-with-redis.mdx';
import SourceCode from '../common-data/microservices-source-code-tip.mdx';
import RedisEnterprise from '../common-data/redis-enterprise.mdx';

<Authors frontMatter={frontMatter} />

<SourceCode />

## What is Interservice Communication?

When building a microservices application, people use a variety of options for communication between services, such as:

1. **Publish/Subscribe** model: In pub/sub (fire and forget) model, a publisher produces messages and subscribers that are _active at the time_ consume those messages. Inactive subscribers cannot receive the messages at a later point in time.
1. **Streaming** : Most microservices applications use an event streaming solution because of:
   - **Message persistence** : Unlike the pub/sub model, messages stored in streams are able to be read by multiple consumers (fan out) at any time. So consumers can always read messages at a later point of time even if they were not active when the message was originally appended to the stream.
   - **Inherent replayability** : Even if a subscriber crashes during the message processing, it can re-read the exact same unacknowledged message from stream. Say the crashed subscriber never comes back online, then the consumer group feature allows consumers to process unacknowledged messages of other consumers after a specified time.
   - **Separation of concerns** : Producers can produce messages to stream at **high speed** separately and consumers can process messages at their own speed separately. This separation of concerns solves both the "fast producer -> slow consumer" and "slow producer -> fast consumer" problem, allowing the scaling of those services independently.

In an event-driven microservices architecture you might have some services that publish an API, and other services that are simply producers and consumers of events with no external API.

## Why You Should Use Redis for Interservice Communication

Consider the following scenario.

You have an e-commerce application which is broken down into different microservices like `create an order`, `create an invoice`, `process a payment`, `fulfill and order`, etc. Microservices will allow separating these commands into different services to scale independently, allowing more customers to process their orders quickly and simultaneously resulting in a better user experience and higher sales volume.

When using microservices, you obviously need some way of communication between them. You might initially consider using a product like **Kafka** for streaming, but the setup for it is rather complicated. What many people don't know about Redis is that it supports streams similar to Kafka. Given that you are likely to use Redis for caching already, it makes sense to also use it for stream processing. To reduce complexity of application architecture and maintenance, **Redis** is a great option for interservice communication. Keep reading for a breakdown of how to use Redis with streams for interservice communication.

## Microservices Architecture for an E-commerce Application

<MicroservicesArchitectureWithRedis />

## Using Redis for Interservice Communication in an Event-driven Architecture

Below is an event flow diagram that outlines how the `orders service` and `payments service` communicate through Redis with streams.

![Microservices streaming with Redis event flow diagram](images/interservice-communication-event-flow-diagram.png)

Let's outline the streams and events used below:

1. The `orders service` inserts order data into the database

   ```json
   {
     "orderId": "01GTP3K2TZQQCQ0T2G43DSSMTD",
     "products": [
       {
         "productId": 11000,
         "qty": 3,
         "productPrice": 3995,
         "productData": {
           "productDisplayName": "Puma Men Slick 3HD Yellow Black Watches",
           "variantName": "Slick 3HD Yellow",
           "brandName": "Puma",
           "ageGroup": "Adults-Men",
           "gender": "Men"
           //...
         }
       },
       {
         "productId": 11001,
         "qty": 2,
         "productPrice": 5450,
         "productData": {
           "productDisplayName": "Puma Men Top Fluctuation Red Black Watches",
           "variantName": "Top Fluctuation Red",
           "brandName": "Puma",
           "ageGroup": "Adults-Men",
           "gender": "Men"
           //...
         }
       }
     ],
     "userId": "USR_4e7acc44-e91e-4c5c-9112-bdd99d799dd3",
     "orderStatusCode": 1, //order created
     "createdOn": {
       "$date": {
         "$numberLong": "1677926697801"
       }
     },
     "createdBy": "USR_4e7acc44-e91e-4c5c-9112-bdd99d799dd3",
     "statusCode": 1
   }
   ```

2. The `orders service` also appends minimal data (orderId, orderAmount & userId) to the `ORDERS_STREAM` to signal new order creation (i.e. it acts as `PRODUCER` of the `ORDERS_STREAM`)

   ![orders-stream](./images/02-orders-stream.png)

3. The `payments service` listens to the `ORDERS_STREAM` and processes payments for new orders, then inserts payment data into the database (i.e it acts as the `CONSUMER` of the `ORDERS_STREAM`)

   ```json
   {
     "paymentId": "6403212956a976300afbaac1",
     "orderId": "01GTP3K2TZQQCQ0T2G43DSSMTD",
     "orderAmount": 22885,
     "paidAmount": 22885,
     "orderStatusCode": 3, //payment successful
     "userId": "USR_4e7acc44-e91e-4c5c-9112-bdd99d799dd3",
     "createdOn": {
       "$date": {
         "$numberLong": "1677926697841"
       }
     },
     "createdBy": "USR_4e7acc44-e91e-4c5c-9112-bdd99d799dd3",
     "statusCode": 1
   }
   ```

4. The `payments service` appends minimal data (orderId,paymentId, orderStatusCode & userId) to the `PAYMENTS_STREAM` to signal a new payment (i.e. it acts as the `PRODUCER` of the `PAYMENTS_STREAM`)
   ![payments-stream](./images/04-payments-stream.png)

5. The `orders service` listens to the `PAYMENTS_STREAM` and updates the orderStatus and paymentId for orders in the database accordingly as the order payment is fulfilled (i.e. it acts as the `CONSUMER` of the `PAYMENTS_STREAM`)

```json
{
  //order collection update
  "orderId": "01GTP3K2TZQQCQ0T2G43DSSMTD",
  "paymentId": "6403212956a976300afbaac1",
  "orderStatusCode": 3 //payment success
  //...
}
```

## E-commerce Application Frontend using Next.js and Tailwind

<MicroservicesEcommerceDesign />

## Building an Interservice Communication Application with Redis and MongoDB

We're using Redis to broker the events sent between the `orders service` and the `payments service`.

### Producer 1 (Orders Service)

Let's look at some of the code in the orders service to understand how it works.

1. Orders are created
2. After order creation, the `orders service` appends minimal data to the `ORDERS_STREAM` to signal new order creation

```typescript
const addOrderIdToStream = async (
  orderId: string,
  orderAmount: number,
  userId: string,
) => {
  const nodeRedisClient = getNodeRedisClient();
  if (orderId && nodeRedisClient) {
    const streamKeyName = 'ORDERS_STREAM';
    const entry = {
      orderId: orderId,
      orderAmount: orderAmount.toFixed(2),
      userId: userId,
    };
    const id = '*'; //* = auto generate
    //xAdd adds entry to specified stream
    await nodeRedisClient.xAdd(streamKeyName, id, entry);
  }
};
```

### Consumer 1 (Payments Service)

3. The `payments service` is listening to the `ORDERS_STREAM`

```typescript
// Below is some code for how you would use Redis to listen for the stream events:

async function listenToStream(
  onMessage: (message: any, messageId: string) => Promise<void>,
) {
  // using node-redis
  const redis = getNodeRedisClient();
  const streamKeyName = 'ORDERS_STREAM'; //stream name
  const groupName = 'ORDERS_CON_GROUP'; // listening consumer group name (custom)
  const consumerName = 'PAYMENTS_CON'; // listening consumer name (custom)
  const readMaxCount = 100;

  // Check if the stream group already exists
  if (!(await redis.exists(streamKeyName))) {
    const idPosition = '0'; //0 = start, $ = end or any specific id
    await nodeRedisClient.xGroupCreate(streamKeyName, groupName, idPosition, {
      MKSTREAM: true,
    });
  }

  // setup a loop to listen for stream events
  while (true) {
    // read set of messages from different streams
    const dataArr = await nodeRedisClient.xReadGroup(
      commandOptions({
        isolated: true,
      }),
      groupName,
      consumerName,
      [
        {
          // you can specify multiple streams in array
          key: streamKeyName,
          id: '>', // Next entry ID that no consumer in this group has read
        },
      ],
      {
        COUNT: readMaxCount, // Read n entries at a time
        BLOCK: 0, // block for 0 (infinite) seconds if there are none.
      },
    );

    for (let data of dataArr) {
      for (let messageItem of data.messages) {
        // process the message received (in our case, perform payment)
        await onMessage(messageItem.message, messageItem.id);

        // acknowledge individual messages after processing
        nodeRedisClient.xAck(streamKeyName, groupName, messageItem.id);
      }
    }
  }
}

// `listenToStream` listens for events and calls the `onMessage` callback to further handle the events.
listenToStream({
  onMessage: processPaymentForNewOrders,
});

const processPaymentForNewOrders: IMessageHandler = async (
  message,
  messageId,
) => {
  /*
   message = {
      orderId: "",
      orderAmount: "",
      userId: "",
    }
    */
  // process payment for new orderId and insert "payments" data to database
};
```

:::note

There are a few important things to note here:

1. Make sure the stream group doesn't exist prior to creating it.
1. Use `isolated: true,` in order to use the blocking version of `XREADGROUP` in [isolated execution](https://github.com/redis/node-redis/blob/master/docs/isolated-execution.md) mode.
1. Acknowledge individual messages after they have been processed to remove them from the pending orders queue and avoid processing them more than once.

:::

### Producer 2 (Payments Service)

4. The `payments service` appends minimal data to `PAYMENTS_STREAM` to signal that a payment has been fulfilled.

```typescript
const addPaymentIdToStream = async (
  orderId: string,
  paymentId: string,
  orderStatus: number,
  userId: string,
) => {
  const nodeRedisClient = getNodeRedisClient();
  if (orderId && nodeRedisClient) {
    const streamKeyName = 'PAYMENTS_STREAM';
    const entry = {
      orderId: orderId,
      paymentId: paymentId,
      orderStatusCode: orderStatus.toString(),
      userId: userId,
    };
    const id = '*'; //* = auto generate
    //xAdd adds entry to specified stream
    await nodeRedisClient.xAdd(streamKeyName, id, entry);
  }
};
```

### Consumer 2 (Orders Service)

5. The `orders service` listens to the `PAYMENTS_STREAM` and updates the order when payments are fulfilled.

```typescript
//Below is some code for how you would use Redis to listen for the stream events:

async function listenToStream(
  onMessage: (message: any, messageId: string) => Promise<void>,
) {
  // using node-redis
  const redis = getNodeRedisClient();
  const streamKeyName = 'PAYMENTS_STREAM'; //stream name
  const groupName = 'PAYMENTS_CON_GROUP'; //listening consumer group name (custom)
  const consumerName = 'ORDERS_CON'; //listening consumer name (custom)
  const readMaxCount = 100;

  // Check if the stream group already exists
  if (!(await redis.exists(streamKeyName))) {
    const idPosition = '0'; //0 = start, $ = end or any specific id
    await nodeRedisClient.xGroupCreate(streamKeyName, groupName, idPosition, {
      MKSTREAM: true,
    });
  }

  // setup a loop to listen for stream events
  while (true) {
    // read set of messages from different streams
    const dataArr = await nodeRedisClient.xReadGroup(
      commandOptions({
        isolated: true,
      }),
      groupName,
      consumerName,
      [
        {
          // you can specify multiple streams in array
          key: streamKeyName,
          id: '>', // Next entry ID that no consumer in this group has read
        },
      ],
      {
        COUNT: readMaxCount, // Read n entries at a time
        BLOCK: 0, // block for 0 (infinite) seconds if there are none.
      },
    );

    for (let data of dataArr) {
      for (let messageItem of data.messages) {
        //process the message received (in our case, updateOrderStatus)
        await onMessage(messageItem.message, messageItem.id);

        // acknowledge individual messages after processing
        nodeRedisClient.xAck(streamKeyName, groupName, messageItem.id);
      }
    }
  }
}

// `listenToStream` listens for events and calls the `onMessage` callback to further handle the events.
listenToStream({
  onMessage: updateOrderStatus,
});

const updateOrderStatus: IMessageHandler = async (message, messageId) => {
  /*
   message = {
      orderId: "",
      paymentId: "",
      orderStatusCode:"",
      userId: "",
    }
    */
  // updates orderStatus and paymentId in database accordingly for the order which has fulfilled payment
  // updateOrderStatusInRedis(orderId,paymentId,orderStatusCode,userId)
  // updateOrderStatusInMongoDB(orderId,paymentId,orderStatusCode,userId)
};
```

:::tip

It's best practice to validate all incoming messages to make sure you can work with them.

:::

For the purposes of our application we are making a call to update the order status in Redis and MongoDB. An alternative option is to use something like RedisGears to synchronize the data between Redis and MongoDB. Doing so would allow you to simply write to Redis, which would then trigger RedisGears to subsequently write to MongoDB. It's a small difference, but many people choose to go this route because of the cleaner implementation and separation of concerns.

## Conclusion

That's all there is to it! You've now seen how to use Redis for streaming as both a producer and a consumer. Hopefully you can draw some inspiration from this tutorial and apply it to your own event streaming application. See below for some additional resources around this topic.

### Additional Resources

- Explore streams in detail in the [Redis University course on Redis Streams](https://university.redis.com/courses/ru202/)
- Check out our e-book on [Understanding Streams in Redis and Kafka â€“ A Visual Guide](https://redis.com/docs/understanding-streams-in-redis-and-kafka-a-visual-guide/)
- [CQRS](/howtos/solutions/cqrs)
- [Query caching](/howtos/solutions/caching)
- [API gateway caching](/howtos/solutions/api-gateway-caching)
- [Redis YouTube channel](https://www.youtube.com/c/Redisinc)
- Clients like [Node Redis](https://github.com/redis/node-redis) and [Redis om Node](https://github.com/redis/redis-om-node) help you to use Redis in Node.js applications.

## Learn More

<RedisEnterprise />
